\subsection{Benchmark conclusion}\label{subsection:benchmark-conclusion}
In conclusion to our benchmark, we can make a global comment on figures \ref{fig:benchmark-n_bplot}, \ref{fig:benchmark-p_bplot}, \ref{fig:benchmark-time_turn}, and \ref{fig:benchmark-time_histo}.

\begin{itemize}[label=$\blacktriangleright$]
    \item First, the documentation about MCTS was clear on how important it is for $n$ to be large. Thus, the main trade-off for humain constraints was on having a large $n$ with realist execution times.
    \item Figure \ref{fig:benchmark-p_bplot} has shown that the only parameter to regulate the execution time was $n$. $p$ does not play a role. A prior result was the fact that the code need to be optimized to be able to run more simulations, and we were able to speed-up the algorithm by 10 just by cleaning code.
    \item Figure \ref{fig:benchmark-n_bplot} has shown that the execution time was linear in $n$, which is coherent because doubling $n$ mean doubling the number of simulations, so doubling total time. 
    \item Figure \ref{fig:benchmark-time_turn} has shown that MCTS takes in average a lot of time in the beginning of the game, and the execution time tends to stabilize after. This is a huge difference compared to minimax and led to the understanding that we can not use MCTS like we use minimax, meaning, we can not just implement the algorithm and let it run in a static way. \\
    
    A possible use of MCTS would be to implementating it alongside another algorithm that would be, like minimax, stable in the first rounds ; or modify the parameters during the run (dumber moves but low $n$ in the first rounds, smarter moves and higher $n$ in the last rounds, etc.), ... 

    \item However, plot \ref{fig:benchmark-time_histo} shows that in average, 90\% of the moves played my MCTS can be stored in 2 buckets of a histogram, which shows a similar behaviour for each game.
\end{itemize}